\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{GeReco: A deep learning approach to static and dynamic gesture recognition}

\author{Andrea Auletta\\
{\tt\small andrea.auletta@studenti.unipd.it}
\and
Marco Bernardi\\
{\tt\small marco.bernardi.11@studenti.unipd.it}
\and
Sebastiano Sanson\\
{\tt\small sebastiano.sanson@studenti.unipd.it}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   This research project aims to investigate the current state of the art in gesture recognition, with an emphasis on both static and dynamic gestures. 
   It proposes an inclusive framework designed to recognize a broad spectrum of gestures, ranging from simple static gestures to complex dynamic ones. 
   The proposed framework has significant potential for applications in various domains, including human-computer interaction, robotics, and virtual reality. 
   Specific applications include human sign language recognition, gesture-based interfaces, and gesture-based game control.
\end{abstract}


%%%%%%%%% BODY TEXT
\section{Introduction}
Gesture recognition is a significant research area in computer vision and machine learning. It can be used in various applications and this is why it is an important topic to study.
The goal of this project is to study, implement and test some approaches to gesture recognition, focusing on both static and dynamic gestures. We also tried 
to implement a real time gesture recognition system using a webcam and the developed models.
\section{Related Work}
There are many apporaches to gesture recognition. What we have done is to study some of them and try to implement or to use transfer learning to adapt them to our problem.
Finally we decided to use Mediapipe \cite{lugaresi2019mediapipeframeworkbuildingperception} \cite{zhang2020mediapipehandsondevicerealtime} to detect static gesture and 
a custom model to detect dynamic gestures taken from \cite{electronics13163233}. This last model is based on Mediapipe, InceptionV3 and a LSTM layer.

\section{Dataset}
Clearly the dataset is a crucial part of the project and obviously we needed two kind of dataset:
\begin{itemize}
   \item A dataset of \textbf{static gestures}: we used a reduced version of the \textit{HaGRID dataset} \cite{Alexander_2024}. The original size dataset
   is too big for our purposes and for our resources, so we decided to use a reduced version of it. The original dataset contains about 550000 FullHD images (716GB)
   divided in 18 classes of gestures. We decided to use only about 2000 images divided in 6 classes of gestures.
   \item A dataset of \textbf{dynamic gestures}: we used the \textit{Depth camera based dataset of hand gestures} \cite{JEERU2022108659}. In this case there are about 4000 videos of 
   6 different gestures.
\end{itemize}

\section{Method}
\subsection{Static gestures}
\subsubsection{Data preprocessing}
- data augmentation
\subsubsection{Model}
- Mediapipe
- transfer learning
\subsection{Dynamic gestures}
\subsubsection{Data preprocessing}
- 10 frames crop hand
- sharpening
- 10 frames on BODY
\subsubsection{Model}
-Mediapipe
-InceptionV3
-LSTM: accept fixed size
\subsection{Real time gesture recognition}

\section{Experiments}

\section{Conclusion}



\begin{itemize}
	\item Introduction (10\%): describe the problem you are working on, why it's important, and an overview of your results.
	\item Related Work (10\%): discuss published work or similar apps that relates to your project. How is your approach similar or different from others?
	\item Dataset (15\%): describe the data you are working with for your project. What type of data is it? Where did it come from? How much data are you working with? Did you have to do any preprocessing, filtering, etc., and why?
	\item Method (30\%): discuss your approach for solving the problems that you set up in the introduction. Why is your approach the right thing to do? Did you consider alternative approaches? It may be helpful to include figures, diagrams, or tables to describe your method or compare it with others.
	\item Experiments (30\%): discuss the experiments that you performed. The exact experiments will vary depending on the project, but you might compare with prior work, perform an ablation study to determine the impact of various components of your system, experiment with different hyperparameters or architectural choices. You should include graphs, tables, or other figures to illustrate your experimental results.
	\item Conclusion (5\%): summarize your key results; what have you learned? Suggest ideas for future extensions.
\end{itemize}	






%-------------------------------------------------------------------------
\subsection{Illustrations, graphs, and photographs}

{\small\begin{verbatim}
   \usepackage[dvips]{graphicx} ...
   \includegraphics[width=0.8\linewidth]
                   {myfile.eps}
\end{verbatim}
}


{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
